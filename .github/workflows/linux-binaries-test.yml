name: linux-binaries-test

on:
  pull_request:
  push:
    branches:
      - master
      - dev
      - ci-bintest-linux
    tags:
      - v*

defaults:
  run:
    shell: bash

jobs:
  #
  # Produce a "full" source-archive, that is, including source from submodules
  #
  # This is done to provide the source-archive for users in environments without
  # submodule access and for the containers in the workflow which does not have
  # a recent enough version of git do pull down the modules
  #
  source-archive-gen:
    runs-on: ubuntu-latest

    steps:
    - name: Grab source
      uses: actions/checkout@v2

    - name: Prepare Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.x'

    - name: Generate Full Source Archive
      run: |
        sudo ./scripts/pkgs/ubuntu-focal.sh
        make clobber gen-src-archive

    - name: Upload source archive
      uses: actions/upload-artifact@v2
      with:
        name: archive-src
        path: builddir/meson-dist/*.tar.gz

  # Grab the source and build on self-hosted, matching the CPU on which it will
  # be tested. This is done, since SPDK/DPDK is build with "-march=native", and
  # thus needs to run on a CPU with the same ISA
  linux-binaries:
    runs-on: self-hosted
    needs: source-archive-gen

    container: debian:bullseye

    steps:
    - name: Self-hosted, prep
      run: |
        rm -rf *
        ls

    - name: Container-prep, get the full-source-archive
      uses: actions/download-artifact@v2
      with:
        name: archive-src

    - name: Unpack the full-source-archive
      run: |
        tar xzf xnvme*.tar.gz --strip 1
        rm xnvme*.tar.gz

    - name: Install build-requirements
      run: |
        source scripts/pkgs/debian-bullseye.sh
        [[ ! -f "/usr/bin/python" ]] && ln -s /usr/bin/python3.8 /usr/bin/python || true

    - name: Configure, the build
      run: |
        make config

    - name: Dump, the compile-commands and machine
      run: |
        cat /proc/cpuinfo
        cat builddir/compile_commands.json || true

    - name: Build!
      run: |
        make

    - name: Build! bin-deb-pkg
      run: |
        make build-deb

    - name: Install
      run: |
        make install

    - name: Execute 'xnvme enum'
      run: xnvme enum

    - name: Execute 'xnvme library-info'
      run: xnvme library-info

    # The is intended for testing and for quick-preview for those that do not
    # want to build from source. It will later be used for installation inside a
    # docker-container, as well as inside of a qemu-guest
    #- name: Upload Archive
    #  uses: actions/upload-artifact@v2
    #  with:
    #    name: archive-bin
    #    path: builddir/*.bin.tar.gz

    - name: Upload Debian Packages
      uses: actions/upload-artifact@v2
      with:
        name: pkg-deb
        path: builddir/meson-dist/*.deb

    - name: Upload fio binary
      uses: actions/upload-artifact@v2
      with:
        name: fio-bin
        path: subprojects/fio/fio

    - name: Upload the SPDK fio io-engines
      uses: actions/upload-artifact@v2
      with:
        name: fio-spdk-ioengines
        path: subprojects/spdk/build/fio/*

    # The git-hub-actions-runner does not cleanup after itself
    - name: Self-hosted, cleanup
      if: always()
      run: rm -rf *

  # Test the pkg-deb built on Debian Bullseye / 11 using CIJOE
  linux-testing:
    needs: linux-binaries

    runs-on: self-hosted
    container:
      image: refenv/qemu-nvme:latest
      options: --privileged

    steps:
    - name: Self-hosted, prep
      run: rm -rf *

    - name: Container-prep, define env.
      run: |
        source /opt/scripts/suitup.sh

        echo "RESULTS=/tmp/results" >> $GITHUB_ENV
        echo "TARGET_ENV=${CIJ_ENVS}/refenv-xnvme-qemu.sh" >> $GITHUB_ENV
        echo "CLOUD_IMG_URL=https://cloud.debian.org/images/cloud/bullseye/daily/latest/debian-11-generic-amd64-daily.qcow2" >> $GITHUB_ENV
    - name: Container-prep, download Debian packages
      uses: actions/download-artifact@v2
      with:
        name: pkg-deb

    - name: Container-prep, download fio binary
      uses: actions/download-artifact@v2
      with:
        name: fio-bin

    - name: Container-prep, download SPDK fio io-engines
      uses: actions/download-artifact@v2
      with:
        name: fio-spdk-ioengines

    - name: Container-prep, start the SSH server
      run: service ssh restart

    - name: CIJOE, re-install as pre-release and install the xNVMe package
      run: |
        pip3 uninstall -y cijoe
        pip3 install --pre cijoe
        pip3 install --pre cijoe-pkg-xnvme

    - name: CIJOE, define and create result folder
      run: |
        mkdir -p ${RESULTS}/

    - name: CIJOE/QEMU, provision guest using Debian cloud image
      run: |
        source /opt/scripts/suitup.sh
        qemu.img_from_url "${CLOUD_IMG_URL}"

    - name: CIJOE/QEMU, start the guest
      run: |
        source /opt/scripts/suitup.sh
        #source "${CIJ_TESTFILES}/qemu6_pcie_nvme_1c2ns_nvm_zns.sh"
        source "${CIJ_TESTFILES}/qemu_setup_nvme_1c2ns_nvm_zrwa.sh"
        qemu_setup_pcie
        QEMU_ARGS_EXTRA="$QEMU_SETUP_PCIE"
        qemu.run

    - name: CIJOE/QEMU, install Debian packages in guest
      run: |
        source /opt/scripts/suitup.sh

        for deb in *.deb; do
          ssh.push "$deb" "/tmp/"
        done

        ssh.cmd "dpkg -i /tmp/*.deb"

    - name: CIJOE/QEMU, dump fio binary and SPDK io-engines in guest
      run: |
        source /opt/scripts/suitup.sh
        ssh.cmd "mkdir /opt/aux"
        ssh.push "fio" "/opt/aux/"
        ssh.push "spdk_nvme" "/opt/aux/"
        ssh.push "spdk_bdev" "/opt/aux/"
        ssh.cmd "find /opt/aux"
        ssh.cmd "chmod +x /opt/aux/fio"

    - name: CIJOE/QEMU, check binaries are available
      if: always()
      run: |
        source /opt/scripts/suitup.sh
        ssh.cmd "hostname || true"
        ssh.cmd "which xnvme || true"
        ssh.cmd "whereis which zoned || true"
        ssh.cmd "xnvme library-info || true"
        ssh.cmd "xnvme enum || true"

    - name: CIJOE/QEMU, run testplans
      if: always()
      run: |
        source /opt/scripts/suitup.sh
        cij_runner \
          --testplan \
          "$CIJ_TESTPLANS/xnvme-zns-zrwa-linux-nvme.plan" \
          "$CIJ_TESTPLANS/xnvme-zns-zrwa-linux-spdk.plan" \
          "$CIJ_TESTPLANS/xnvme-base-linux.plan" \
          "$CIJ_TESTPLANS/xnvme-base-spdk.plan" \
          "$CIJ_TESTPLANS/xnvme-nvm-spdk.plan" \
          "$CIJ_TESTPLANS/xnvme-nvm-linux-nvme.plan" \
          "$CIJ_TESTPLANS/xnvme-nvm-linux-null.plan" \
          "$CIJ_TESTPLANS/xnvme-zns-spdk.plan" \
          "$CIJ_TESTPLANS/xnvme-zns-linux-nvme.plan" \
          "$CIJ_TESTPLANS/xnvme-zns-linux-null.plan" \
          --env ${TARGET_ENV} \
          --output ${RESULTS}

    - name: CIJOE/QEMU, kill the guest
      if: always()
      run: |
        source /opt/scripts/suitup.sh
        qemu.kill

    - name: CIJOE, result-log-dump on error
      if: failure()
      run: find ${RESULTS} -name "*.log" | xargs cat

    - name: CIJOE, generate report from results
      if: always()
      run: |
        source /opt/scripts/suitup.sh
        cij_reporter --output "${RESULTS}"

    - name: CIJOE, upload test results and report
      uses: actions/upload-artifact@v2
      if: always()
      with:
        name: test-results
        path: ${{ env.RESULTS }}/*

    # The git-hub-actions-runner does not cleanup after itself
    - name: Self-hosted, cleanup
      if: always()
      run: rm -rf *
